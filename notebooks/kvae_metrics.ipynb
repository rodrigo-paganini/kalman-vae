{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "254de86f",
   "metadata": {},
   "source": [
    "# Extraction of model metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "86acb541",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc9b7b8d",
   "metadata": {},
   "source": [
    "## Load a model and data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c89e695b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ Loaded checkpoint from epoch 6\n",
      "  Train loss: 7.899650\n",
      "  Val loss: 7.172936\n",
      "\n",
      "Model loaded on: cpu\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from pathlib import Path\n",
    "import yaml\n",
    "\n",
    "from kvae.model.model import KVAE\n",
    "from kvae.utils.config import KVAEConfig\n",
    "from kvae.train.utils import parse_device, build_dataloaders\n",
    "from kvae.train.train import evaluate\n",
    "from kvae.train.imputation import impute_epoch\n",
    "\n",
    "\n",
    "def load_checkpoint(checkpoint_path, device='auto'):\n",
    "    \"\"\"\n",
    "    Load a trained KVAE model from checkpoint.\n",
    "    \n",
    "    Args:\n",
    "        checkpoint_path: Path to checkpoint file (.pt)\n",
    "        device: Device to load model on ('auto', 'cuda', 'cpu', 'mps')\n",
    "    \n",
    "    Returns:\n",
    "        model: Loaded KVAE model\n",
    "        checkpoint: Full checkpoint dictionary with training info\n",
    "        device: The actual device being used\n",
    "    \"\"\"\n",
    "    checkpoint_path = Path(checkpoint_path)\n",
    "    if not checkpoint_path.exists():\n",
    "        raise FileNotFoundError(f\"Checkpoint not found: {checkpoint_path}\")\n",
    "    \n",
    "    device = parse_device(device)\n",
    "    \n",
    "    # Load checkpoint\n",
    "    checkpoint = torch.load(checkpoint_path, map_location=device)\n",
    "    \n",
    "    # Initialize model with config\n",
    "    cfg = KVAEConfig()\n",
    "    model = KVAE(cfg).to(device)\n",
    "    \n",
    "    # Load weights\n",
    "    model.load_state_dict(checkpoint['model_state'])\n",
    "    model.eval()\n",
    "    \n",
    "    print(f\"✓ Loaded checkpoint from epoch {checkpoint['epoch']}\")\n",
    "    print(f\"  Train loss: {checkpoint['train_loss']:.6f}\")\n",
    "    print(f\"  Val loss: {checkpoint['val_loss']:.6f}\")\n",
    "    \n",
    "    return model, checkpoint, device\n",
    "\n",
    "\n",
    "# Example usage:\n",
    "# runs/20251204-214705\n",
    "# runs/20251212-201237\n",
    "# runs/20251212-205425\n",
    "runs_path = Path(\"../runs/20251212-205425\")\n",
    "checkpoint_path = runs_path / \"checkpoints/kvae-best.pt\"\n",
    "\n",
    "model, ckpt, device = load_checkpoint(checkpoint_path, device='cpu')\n",
    "print(f\"\\nModel loaded on: {device}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a346cc87",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Configuration:\n",
      "  dataset: {'kwargs': {'load_in_memory': True, 'normalize': False, 'seq_len': 20}, 'num_workers': 6, 'path': '/Users/rodrigopaganini/master/data/pgm/kvae/box.npz', 'type': 'pymunk', 'val_split': 0.2}\n",
      "  training: {'add_imputation_plots': True, 'batch_size': 32, 'ckpt_every': 5, 'device': 'mps', 'gpus': 1, 'logdir': 'runs', 'lr': 0.007, 'max_epochs': 100, 'pretrain_vae_epochs': 0, 'seed': 10, 'warmup_epochs': 5}\n",
      "  transforms: {'add_noise_std': 0.0}\n",
      "Train batches: 125\n",
      "Val batches: 32\n",
      "Using device: cpu\n"
     ]
    }
   ],
   "source": [
    "# Load config from the run directory\n",
    "config_path = runs_path / \"config.yaml\"\n",
    "\n",
    "with open(config_path, 'r') as f:\n",
    "    config = yaml.safe_load(f)\n",
    "\n",
    "print(\"Configuration:\")\n",
    "for key, value in config.items():\n",
    "    print(f\"  {key}: {value}\")\n",
    "\n",
    "# Load data\n",
    "train_loader, val_loader = build_dataloaders(\n",
    "    config['dataset'], \n",
    "    batch_size=config['training']['batch_size']\n",
    ")\n",
    "\n",
    "print(f\"Train batches: {len(train_loader)}\")\n",
    "print(f\"Val batches: {len(val_loader)}\")\n",
    "print(f\"Using device: {device}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a253d87",
   "metadata": {},
   "source": [
    "## Define metrics and evaluate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ba60473",
   "metadata": {},
   "outputs": [],
   "source": [
    "def fraction_of_incorrect_pixels(y_true, y_pred):\n",
    "    \"\"\"\n",
    "    Compute the fraction of incorrect pixels between two binary images.\n",
    "    Args:\n",
    "        y_true: Ground truth binary image (numpy array or torch tensor)\n",
    "        y_pred: Predicted binary image (numpy array or torch tensor)\n",
    "    Returns:\n",
    "        Fraction of incorrect pixels (float)\n",
    "    \"\"\"\n",
    "    if isinstance(y_true, torch.Tensor):\n",
    "        y_true = y_true.cpu().numpy()\n",
    "    if isinstance(y_pred, torch.Tensor):\n",
    "        y_pred = y_pred.cpu().numpy()\n",
    "    \n",
    "    incorrect_pixels = np.sum(y_true != y_pred)\n",
    "    total_pixels = y_true.size\n",
    "    \n",
    "    return incorrect_pixels / total_pixels if total_pixels > 0 else 0.0\n",
    "metrics_functions = {\n",
    "    \"fraction_of_incorrect_pixels\": fraction_of_incorrect_pixels,\n",
    "}\n",
    "\n",
    "def evaluate_metrics(model, loader, device, metrics_functions, mask_sampling_fn, output_key=\"x_recon\"):\n",
    "    model.eval()\n",
    "    n_batches  = 0\n",
    "\n",
    "    total_metrics = {key: 0.0 for key in metrics_functions.keys()}\n",
    "    for batch in tqdm(loader, desc=\"Evaluating:\"):\n",
    "        model.kalman_filter.dyn_params.reset_state()\n",
    "\n",
    "        x = batch[\"images\"].float().to(device)\n",
    "        B, T = x.shape[:2]\n",
    "\n",
    "        # Fully observed evaluation (no masking)\n",
    "        mask = mask_sampling_fn(B, T).to(device)\n",
    "        with torch.no_grad():\n",
    "            outputs = model(x, mask=mask)\n",
    "            for metric_name, metric_fn in metrics_functions.items():\n",
    "                total_metrics[metric_name] += metric_fn(x, outputs[output_key])\n",
    "            del outputs\n",
    "        n_batches += 1\n",
    "\n",
    "    denom = max(n_batches, 1)\n",
    "    mean_metrics = {k: v / denom for k, v in total_metrics.items()}\n",
    "\n",
    "    return mean_metrics\n",
    "\n",
    "\n",
    "def evaluate_impute_metrics(model, loader, device, metrics_functions, mask_sampling_fn, output_key=\"x_recon\"):\n",
    "    model.eval()\n",
    "    n_batches  = 0\n",
    "\n",
    "    total_metrics = {key: 0.0 for key in metrics_functions.keys()}\n",
    "    for batch in tqdm(loader, desc=\"Evaluating:\"):\n",
    "        model.kalman_filter.dyn_params.reset_state()\n",
    "\n",
    "        x = batch[\"images\"].float().to(device)\n",
    "        B, T = x.shape[:2]\n",
    "\n",
    "        # Fully observed evaluation (no masking)\n",
    "        mask = mask_sampling_fn(B, T).to(device)\n",
    "        print(\"mask percentage:\", mask.mean().item())\n",
    "        with torch.no_grad():\n",
    "            outputs = model.impute(x, mask)\n",
    "            for metric_name, metric_fn in metrics_functions.items():\n",
    "                total_metrics[metric_name] += metric_fn(x, outputs[output_key])\n",
    "            del outputs\n",
    "        n_batches += 1\n",
    "\n",
    "\n",
    "    denom = max(n_batches, 1)\n",
    "    mean_metrics = {k: v / denom for k, v in total_metrics.items()}\n",
    "\n",
    "    return mean_metrics\n",
    "\n",
    "full_mask_sampling = lambda B, T: torch.ones(B, T, device=device, dtype=torch.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6a434a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics = evaluate_metrics(model, val_loader, device, metrics_functions, full_mask_sampling)\n",
    "print(\"Evaluation Metrics:\")\n",
    "for metric_name, metric_value in metrics.items():\n",
    "    print(f\"  {metric_name}: {metric_value:.6f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bfa5f868",
   "metadata": {},
   "outputs": [],
   "source": [
    "dropout_rate = 0.5\n",
    "dropout_mask_sampling = lambda B, T: (torch.rand(B, T, device=device) < (1 - dropout_rate)).float()\n",
    "\n",
    "metrics = evaluate_impute_metrics(model, val_loader, device, metrics_functions, dropout_mask_sampling, \"x_filtered\")\n",
    "print(\"Evaluation Metrics:\")\n",
    "for metric_name, metric_value in metrics.items():\n",
    "    print(f\"  {metric_name}: {metric_value:.6f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ce1630a",
   "metadata": {},
   "outputs": [],
   "source": [
    "dropout_metrics = {dr: {}  for dr in torch.linspace(0.2, 1.0, steps=5)}\n",
    "for drop_rate in dropout_metrics.keys():\n",
    "    dropout_mask_sampling = lambda B, T: (torch.rand(B, T, device=device) < (1 - drop_rate)).float()\n",
    "    dropout_metrics[drop_rate] = evaluate_metrics(model, val_loader, device, metrics_functions, dropout_mask_sampling)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3d5040f",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(8, 6))\n",
    "for metric_name in metrics_functions.keys():\n",
    "    values = [dropout_metrics[dr][metric_name] for dr in dropout_metrics.keys()]\n",
    "    plt.plot(list(dropout_metrics.keys()), values, marker='o', label=metric_name)\n",
    "plt.xlabel(\"Dropout Rate\")\n",
    "plt.ylabel(\"Metric Value\")\n",
    "plt.title(\"Metrics vs Dropout Rate\")\n",
    "plt.legend()\n",
    "plt.grid()\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
